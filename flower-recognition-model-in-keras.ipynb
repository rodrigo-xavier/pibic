{"cells":[{"metadata":{"_uuid":"93b04367aba7204b36de0a0ef5babd0dbacf9cf5"},"cell_type":"markdown","source":"## Classification of Flower image\n\nThis dataset contain image of different type of flower , there are five type flowers.\n* Sunflower\n* Tulip\n* Daisy\n* Rose\n* Dandelion\n\nHere to to solve this Classification problem we will create a CNN model and train it with given image dataset, then we will take some image from dataset and try to predict its accuracy."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom PIL import  Image\n%matplotlib inline\nplt.style.use('fivethirtyeight')\n\nfrom PIL import Image\n# Importing the Keras libraries and packages\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom tensorflow.contrib.keras.api.keras.callbacks import Callback\nfrom tensorflow.contrib.keras.api.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.contrib.keras import backend\nfrom keras.optimizers import Adam\n\nimport os\n\nprint(os.listdir(\"../input/flowers/flowers/\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"\nscript_dir = os.path.dirname(\".\")\ntraining_set_path = os.path.join(script_dir, '../input/flowers/flowers/')\ntest_set_path = os.path.join(script_dir, '../input/flowers/flowers/')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"50146beecf3aa13f1ec33fe3f37a587f5e91b802"},"cell_type":"markdown","source":"# Initialising the CNN\n"},{"metadata":{"trusted":true,"_uuid":"c8a527dabc7a180e320b357d79ea44d47af827c9"},"cell_type":"code","source":"classifier = Sequential()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b0fe45b64c89d7d36e303d348b97ae4a57bd0fc3"},"cell_type":"markdown","source":"# Step 1 - Convolution"},{"metadata":{"trusted":true,"_uuid":"6c2f0ddac6806198039040f196f697cab9bc0d9c"},"cell_type":"code","source":"input_size = (256, 256)\nclassifier.add(Conv2D(32, (3, 3), input_shape=(256,256,3), activation='relu'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c69edf8e7bc6bca18d7d964b1100468585b8c41"},"cell_type":"markdown","source":"# Step 2 - Pooling"},{"metadata":{"trusted":true,"_uuid":"c09dd6d33429d6029cae3e89254779b3a6d91042"},"cell_type":"code","source":"classifier.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\"))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c050eebd61db0c0e0b21de1483f18763a7482a73"},"cell_type":"markdown","source":"# Adding a second convolutional layer\n"},{"metadata":{"trusted":true,"_uuid":"5633df9bf446e25de2cc70685a8097d4801ebc02"},"cell_type":"code","source":"classifier.add(Conv2D(32, (3, 3), activation='relu'))\nclassifier.add(MaxPooling2D(pool_size=(2, 2)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6df778d90c1266f7047c21d20297f3ccd8261afc"},"cell_type":"markdown","source":"# Adding a third convolutional layer\n"},{"metadata":{"trusted":true,"_uuid":"a7bda831c806d3e86a2379ed25bf36256cdcbeb8"},"cell_type":"code","source":"classifier.add(Conv2D(64, (3, 3), activation='relu'))\nclassifier.add(MaxPooling2D(pool_size=(2, 2)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b880f8feba063aa9d0b5ecccf42e7dd127ac92c"},"cell_type":"markdown","source":"# Step 3 - Flattening\n"},{"metadata":{"trusted":true,"_uuid":"033313b45e7554644634a92ffe53b65ad4a81f0b"},"cell_type":"code","source":"classifier.add(Flatten())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e56169585611d57fb27e24a0d1bc4d28db68f13b"},"cell_type":"markdown","source":"# Step 4 - Full connection\n"},{"metadata":{"trusted":true,"_uuid":"1f50aed068703686bbd7caed618c7bd33062824a"},"cell_type":"code","source":"classifier.add(Dense(units=64, activation='relu'))\nclassifier.add(Dropout(0.5))\nclassifier.add(Dense(units=5, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"69d802407f7b258225d0f30aaaf9d62556898425"},"cell_type":"markdown","source":"# Compiling the CNN\n"},{"metadata":{"trusted":true,"_uuid":"32382bc8d97a42bfd2340a56281da4544bae8975"},"cell_type":"code","source":"opt = Adam(lr=1e-3, decay=1e-6)\nclassifier.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8883b57a357d2af5c69ecb123b02cf2f77839deb"},"cell_type":"markdown","source":"# Data preprocessing\nRead  image data and split it in two part training and test.\n\n"},{"metadata":{"trusted":true,"_uuid":"0e176c0c03b46b30d7f47c0eeae9a6a5cf65c25a"},"cell_type":"code","source":"batch_size = 32\n\ntrain_datagen = ImageDataGenerator(rescale=1. / 255,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255, validation_split=0.33)\n\ntraining_set = train_datagen.flow_from_directory(training_set_path,\n                                                 target_size=input_size,\n                                                 batch_size=batch_size,\n                                                 subset=\"training\",\n                                                 class_mode='categorical')\n\n\n\ntest_set = test_datagen.flow_from_directory(test_set_path,\n                                            target_size=input_size,\n                                            batch_size=batch_size,\n                                            subset=\"validation\",\n                                            class_mode='categorical')\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f4e3836c64df2233d140fbbce2ee6e2e65dd5ea0"},"cell_type":"markdown","source":"# Summary\n"},{"metadata":{"trusted":true,"_uuid":"4c8dd2909a0a1a84b18d5ad47d195691ce274583"},"cell_type":"code","source":"\nclassifier.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9a51e78407c776fabebebfde12a59847eda2673e"},"cell_type":"markdown","source":"\n# Part 2 - Fitting the CNN to the images"},{"metadata":{"trusted":true,"_uuid":"7b53263dbc1345e2b1fe668d5d20b8be288b0559"},"cell_type":"code","source":"\n\nmodel_info = classifier.fit_generator(training_set,\n                         steps_per_epoch=1000/batch_size,\n                         epochs=90,\n                         validation_data=test_set,\n                         validation_steps=100/batch_size,\n                         workers=12)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"034dcaa707a5cfcb9e896b4584ba0fb5df980b90"},"cell_type":"markdown","source":"\n"},{"metadata":{"trusted":true,"_uuid":"4e8290ee78545e678770cb715e17075dfc0d9116"},"cell_type":"markdown","source":"##  Accuracy or Loss as a Function of Number of Epoch\n"},{"metadata":{"_uuid":"b21e71c1492f0608df4b85b9e4fe2cb679fe8238","trusted":true},"cell_type":"code","source":"def plot_model_history(model_history):\n    fig, axs = plt.subplots(1,2,figsize=(15,5))\n    # summarize history for accuracy\n    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy')\n    axs[0].set_xlabel('Epoch')\n    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n    axs[0].legend(['train', 'val'], loc='best')\n    # summarize history for loss\n    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss')\n    axs[1].set_xlabel('Epoch')\n    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n    axs[1].legend(['train', 'val'], loc='best')\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a3bfe0999510403f7d4e7c12458be6e4fdd9d34"},"cell_type":"code","source":"plot_model_history(model_info)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e5dfe2ac1a95fb85ac573e2102b493e8fb33ddd4"},"cell_type":"markdown","source":"That's all i have. I hope you enjoyed this.  if you find this kernel helpful, please upvote."},{"metadata":{"trusted":true,"_uuid":"fab1436e911012566bf39b10a281e425d775ffe1"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}